# --------------------------------------------------------
#
#  ***Oxford Mathematical Brain Modeling Group***
#
#   [Cosica thresholding to FSL connectivity matrices]
#     https://www.michelecoscia.com/?page_id=287
#
#  FSL: https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/FslInstallation
#
#       -or-
#       sudo apt update
#       sudo apt-get install fsl
#       sudo apt-get upgrade
#
#
#  Authors:
#  ================================================
#     Pavan Chaggar       chaggar@maths.ox.ac.uk
#                    ----
#     Travis B. Thompson  thompsont@maths.ox.ac.uk
#                    ----
#     Alain Goriely
#
#
# Mentions:
# =================================================
# Based on code from the paper
#	Network Backboning with Noisy Data: https://arxiv.org/abs/1701.07336
#	The Impact of Projection and Backboning on Network Topologies: https://arxiv.org/abs/1906.09081
#
# A review of network sparsification techniques:
#	https://link.springer.com/article/10.1007/s13278-016-0332-2
#
# ---------------------------------------------------------
# ---------------------------------------------------------
# This script is a multi-threaded version of 2-Cosica-Threshold-to-FSL
# 	and does the following (using multiple threads)
#
#   1. Reads in Cosica-formatted FSL connectivity matrices
#       as generated by 1-FSL-to-Cosica
#   2. Applies various thresholds using backboning.py
#      	Credit: Michele Cosica, https://www.michelecoscia.com/?page_id=287
#		Review of network sparsification techniques:
#			https://link.springer.com/article/10.1007/s13278-016-0332-2
#   3. Outputs the FSL-formatted (symmetric) connectivity matrices for further processing
#-----------------------------------------------------------


import os
import sys
import pandas
import numpy as np
import shutil


# ----------------------------------
import threading
import time
import concurrent.futures
# references on threading:
# https://www.digitalocean.com/community/tutorials/how-to-use-threadpoolexecutor-in-python-3
# https://realpython.com/intro-to-python-threading/
#----------------------------------

# Copyright Michele Cosica
# https://www.michelecoscia.com/?page_id=287
from thresholding import backboning
#----------------------------------


# ----- Connectome and scale
parcellationScale = 5
connectome = "standard_connectome"

#-----------------------------------------------------------
#                   Directory structure
#-----------------------------------------------------------

#	[Do not modify]
#    > The directory of the current script
scriptdir = os.path.dirname(__file__)

# -..-..-..-..-..-
# [No need to modify if running from within the repository structure]
#   > The relative directory (to this script) where you have stored
#   > the FSL connectome connectivity matrix data to be processed by this script
relative_subjectroot = f"../{connectome}/scale{parcellationScale}/subjects/"

#          > Create the subject root directory
fslsubjectroot = os.path.join(scriptdir, relative_subjectroot)

# -..-..-..-..-..-
# [Modify to match 1-FSL-to-Cosica.py]
# 	> The relative directory where the reformatted subject files are stored.
#	> (reformatted subject files can be generated using 1-FSL-to-Cosica.py)
relative_cosica_subject_root = "cosicaformatted/"

# -..-..-..-..-..-
# [Modify]	> The relative directory where you want to store the finished results
relative_finished_results_root = "fslformatted/"

# -..-..-..-..-..-
# [Modify]	> Rescale results using the geometric mean
#				True: Compute the geometric mean of the weights and rescale as weight = original / geom. mean
#				False: Output the raw (unscaled) weight
#				Note: rescaling by the geometric mean is equivalent to rescaling by mean of the
#						log normal distribution of the weights.
rescale_with_geometric_mean = True


# -..-..-..-..-..-
# [Modify]	> Rescale results using the geometric mean
#	Specify the number of threads to use in processing the data
#   Suggestion: Start with one thread, or one thread per CPU core on your machine
nThreads = 2

# -..-..-..-..-..-
#	[Do not modify]
#    > These are the file names of the connectivity and length matrices output by FSL.  This should
#    > not need to be modified (these are the names hard-coded in 1-FSL-to-Cosica.py)
cosicaInput     = "fdt_network_matrix-cosica"
cosicaStatsInput= "fslstats-cosica"
fdtconnectivity = "fdt_network_matrix"


# ---------------------------------------------------------


# ----------------------------------------------------------------
#                         Helper Functions
#                         (Do Not Modify)
# ----------------------------------------------------------------

# A simple progress bar
def printProgressBar(iteration, total, prefix='', suffix='', decimals=1, length=100, fill='â–ˆ', printEnd="\r"):
	"""
    Call in a loop to create terminal progress bar
    @params:
        iteration   - Required  : current iteration (Int)
        total       - Required  : total iterations (Int)
        prefix      - Optional  : prefix string (Str)
        suffix      - Optional  : suffix string (Str)
        decimals    - Optional  : positive number of decimals in percent complete (Int)
        length      - Optional  : character length of bar (Int)
        fill        - Optional  : bar fill character (Str)
        printEnd    - Optional  : end character (e.g. "\r", "\r\n") (Str)
    """
	percent = ("{0:." + str(decimals) + "f}").format(100 * (iteration / float(total)))
	filledLength = int(length * iteration // total)
	bar = fill * filledLength + '-' * (length - filledLength)
	print('\r%s |%s| %s%% %s' % (prefix, bar, percent, suffix), end=printEnd)
	# Print New Line on Complete
	if iteration == total:
		print()

# Any paths input by the user will be formatted according to
# script expectations by encapsulating with this function.
def fixpath(pathstr):
    if pathstr[-1] != '/':
        pathstr = pathstr + '/'
    return pathstr

# Performs various thresholdings using Cosica's backboning library
# (backboning.py from https://www.michelecoscia.com/?page_id=287)
def generateCosicaThresholds(dir,fname):
	dir = fixpath(dir)
	original_table, original_nodes, original_edges = backboning.read(dir + fname, 'nij', triangular_input=True, undirected=True, consider_self_loops=False)

	#---------------------------------------------------
	#         Diagnostics and interaction
	#---------------------------------------------------
	# You can view the table if you wish.  To do so, you
	# will need the tabulate python package.
	# pip3 install tabulate
	# Then uncomment the line below
	#print(table.to_markdown())


	# Uncomment the below to plot see/check/verify that
	# the weights are distributed in log normal fashion
	#plt.figure(1)
	#logtab = np.log(original_table["nij"])
	#logtab.plot.hist(bins=100)
	#plt.show()
	#----------------------------------------------------


	#====================================================================================
	#                             Naive method thresholding
	#====================================================================================
	# Here we simply compute a score as entry/max_entry and keep everything above a certain
	# threshold (using Cosica's same threshold function)

	maxentry = original_table["nij"].max()
	nvtab = original_table.copy(deep=True)

	# Compute the score (percentage of max entry)
	nvtab["score"] = nvtab["nij"] / maxentry

	if os.path.exists(dir + "NAIVE"):
		shutil.rmtree(dir + "NAIVE")

	os.mkdir(dir + "NAIVE")

	tauThr = [0.05, 0.1, 0.2, 0.4, 0.8]

	for tau in tauThr:
		taubackbone = backboning.thresholding(nvtab,tau)
		folder = dir + "NAIVE/"
		method = f"{fdtconnectivity}-NAIVE-{tau}"
		backboning.write(taubackbone,"nij", method, folder)

	#====================================================================================
	#                           Methods for noise-free edge weights
	#                                 but noisy structure
	#====================================================================================

	#------------------------------------------------------------------------------------
	#                                Doubly Stochastic
	#                       https://www.pnas.org/content/106/26/E66
	#------------------------------------------------------------------------------------
	# From the short letter, it appears that this is an iterative approach to Serano's
	# disparity filter (which is computed below).  Thus, the score (for thresholding) here
	# (i.e. the alpha score) is similar to that case (c.f. the `Disparity filter
	# thresholding' technique below).
	#
	# !! We observe scores with a maximum of approximately 0.35 in the results.  So we
	#	take this into account in our thresholds. A threshold of 0.01
	#	only retains ~100 edges so we go lower.  We also observe that thresholds of
	#	0.0001, 0.001 and 0.01 all produce the same edge count; we don't a change
	#   (which is only slight) until 0.1

	if os.path.exists(dir + "DS"):
		shutil.rmtree(dir + "DS")

	os.mkdir(dir + "DS")

	dsThr = [0.01, 0.1, 0.2]

	dstab = backboning.doubly_stochastic(original_table, undirected=True)

	for d in dsThr:
		dsbackbone = backboning.thresholding(dstab,d)
		folder = dir + "DS/"
		method = f"{fdtconnectivity}-DS-{d}"
		backboning.write(dsbackbone,"nij", method, folder)


	#------------------------------------------------------------------------------------
	#                           High-Salience Skeleton
	#                  https://www.nature.com/articles/ncomms1847
	#------------------------------------------------------------------------------------
	# The high-salience skeleton computes a score (called the salience) for each link based
	# on examining the shortest paths between nodes computed using the reciprocal of the
	# original edge weights.  Edges which are "highly salient" have S approx 1 and are
	# important to the network; conversely, edges with S approx 0 are not deemed important
	# for understand the network at large and can be discarded. The paper above (c.f.
	# figure 2C) shows that biological (neural is in the figure) networks typically
	# cluster around 0 and 1 with a long flat stretch in between.  Thus, one would expect
	# the clusters around 1 to be the most significant.
	#
	# !! However, running the HSS procedure on the FSL connectome data shows a maximum
	#	around S = 0.5 (i.e. S does not approach 1).  The HSS aggressively removes edges
	# 	so we take a fairly small minimum (after initially looking at the output number
	#	of edges for a threshold of 0.3 which only retained ~58 edges in the full graph)
	#	We also noted that the graph does not change below the threshold of 0.5*1e-3 so
	# 	there is no need in thresholding under this


	if os.path.exists(dir + "HSS"):
		shutil.rmtree(dir + "HSS")

	os.mkdir(dir + "HSS")

	sI   = [1e-3, 1e-2, 1e-1, 0.2]
	sThr = [si * 0.5 for si in sI]

	hsstab = backboning.high_salience_skeleton(original_table, undirected=True)

	for S in sThr:
		hssbackbone = backboning.thresholding(hsstab,S)
		folder = dir + "HSS/"
		method = f"{fdtconnectivity}-HSS-{S}"
		backboning.write(hssbackbone,"nij", method, folder)


	#====================================================================================
	#                           Methods for noisy edge weights
	#                               with noisy structure
	#====================================================================================

	#------------------------------------------------------------------------------------
	#                           Noise Corrected Thresholding
	#                                 NC method from
	#   https://www.michelecoscia.com/wp-content/uploads/2017/01/20170124backboning.pdf
	#------------------------------------------------------------------------------------
	# The delta (threshold) values that approximately correspond to
	# p-values (for significant edges) of 1e-1, 5e-2 and 1e-2 are 1.28, 1.64, and 2.32
	# c.f. https://www.michelecoscia.com/wp-content/uploads/2017/01/20170124backboning.pdf
	# (discussion under figure 3).

	if os.path.exists(dir + "NC"):
		shutil.rmtree(dir + "NC")

	os.mkdir(dir + "NC")

	#deltaThr = [0.5, 1.0, 1.28, 1.64, 2.0, 2.32]
	deltaThr = [1.28, 1.64, 2.32]

	nctab = backboning.noise_corrected(original_table, undirected=True)


	for delta in deltaThr:
		deltabackbone = backboning.thresholding(nctab,delta)
		folder = dir + "NC/"
		method = f"{fdtconnectivity}-NC-{delta}"
		backboning.write(deltabackbone,"nij", method, folder)


	#------------------------------------------------------------------------------------
	#                        Disparity filter Thresholding
	#                  method from https://www.pnas.org/content/106/16/6483
	#------------------------------------------------------------------------------------
	# The disparity filter is a local (nodal) filter that retains edges at a node
	# based on rejecting a null hypothesis that they were drawn randomly from a uniform
	# (noise) distribution.  The filtering threshold is "alpha".  With lower alpha, more
	# edges are rejected.  Alpha is a probability and so should satisfy 0 < alpha <= 1.
	# The authors have shown nice results on non-noisy networks for alpha as low as 0.003.
	# However, Cocisa nodes (see the NC method PDF paper above) that the disparity filter
	# can fare poorly on noisy (synthetic) networks when compared to the NC method.
	#--- --- --- --- --- --- --- --- --- --- --- --- --- ---
	# Important note:  The way that Cosica has implemented his generic threshold algorithm
	# 	inverts the "alpha" parameter behavior from the original PNAS paper (cited above).
	#	Namely, Cosica calculates the local alpha_ij score.  In the PNAS paper, an edge is
	#	kept if 1 - alpha_ij < alpha where alpha is a global parameter and alpha_ij closer
	#	to one is more significant.  Thus, as alpha-->0 the filter becomes more restrictive
	#	in the original paper.
	#
	#	However, Cosica's thresholding method is generic and keeps and edge if and only if
	#	"score > threshold".  In this case, "score" is alpha_ij.  Thus, the method becomes
	#	more restrictive as we *increase* the threshold in this case.
	#------------------------------------------------------------------------------------

	if os.path.exists(dir + "DF"):
		shutil.rmtree(dir + "DF")

	os.mkdir(dir + "DF")

	#alphaThr = [0.05, 0.1, 0.2, 0.4, 0.6, 0.7, 0.8]
	alphaThr = [0.2, 0.4, 0.8]

	dftab = backboning.disparity_filter(original_table, undirected=True)

	for alpha in alphaThr:
		dfbackbone = backboning.thresholding(dftab,alpha)
		folder = dir + "DF/"
		method = f"{fdtconnectivity}-DF-{alpha}"
		backboning.write(dfbackbone, "nij", method, folder)

# now we need to convert the Cosica-formatted files back to the FSL format
# and output them to the
def convertCosicaToFSL():

	#------ Begin internal function definition --------
	def processSubject(subj):
		# remove the finished results directory for this subject if
		# it exists -- we will create a fresh one

		outdirRoot = fixpath(relative_finished_results_root) + subj
		if os.path.exists(outdirRoot):
			shutil.rmtree(outdirRoot)

		os.mkdir(outdirRoot)

		subjdirIn = fixpath(relative_cosica_subject_root) + subj

		# Read in the original FSL stats for this subject matrix.  These
		#	are the arithmetic and geometric means (of non-zero entries)
		#	and the number of ROI
		subjFSLstats = pandas.read_csv(fixpath(subjdirIn) + cosicaStatsInput, sep='\t')
		nROI = int(subjFSLstats["nROI"])
		amean = float(subjFSLstats["amean"])
		gmean = float(subjFSLstats["gmean"])

		dirlevel = 0
		for rootdir, methods, files in os.walk(subjdirIn):
			dirlevel += 1

			if dirlevel == 1:
				for method in methods:
					methodDirOut = fixpath(outdirRoot) + method

					# We don't have to worry about whether or not
					# the method directory exists since we  have
					# already (above) wiped the entire output
					# directory tree for the subject
					os.mkdir(methodDirOut)

					methodDirIn = fixpath(subjdirIn) + method
					filesToConvert = os.listdir(methodDirIn)

					for f in filesToConvert:
						# first we need to extract the threshold.  We will
						# use this as a directory name
						# The files will have a name like
						# [something]-method-Threshold.csv
						extensionNdx = f.find(".csv")
						thrNdx = f.rfind("-")
						thrStr = f[thrNdx+1:extensionNdx]

						# we dont have to worry about whether or not a threshold
						# output directory exists because we already removed the
						# entire output directory tree (above) if it existed.
						outputDir = fixpath(methodDirOut) + thrStr
						os.mkdir(outputDir)

						# read in the reformatted dataframe.  They are tab delimited
						#	vis-a-vis Cosica's (file format) convention.  The column
						#	indices in this dataframe are
						#	0: src id -- this is the (zero based) row index of the connectivity matrix
						#	1: trg id -- this is the (zero based) column index of the connectivity matrix
						#	2: nij	  -- this is the edge weight
						#	3: score  -- this is the score assigned to the edge by the respective
						#					thresholding procedure (we don't need this anymore)
						#	Note: that Cosima's code only keeps entries where nij was nonzero and we are
						#	responsible for building a symmetric matrix.  That is, Cosima's code only
						#	retains (src,trg) = nij and does not duplicate (trg,src)
						fdat = pandas.read_csv(fixpath(methodDirIn) + f, sep="\t")

						normalizer = 1.0

						if rescale_with_geometric_mean == True:
							# comute the geometric mean of the weights column
							#normalizer = stats.gmean(fdat.iloc[:,2], axis=0)
							normalizer = gmean

						fslmat = np.zeros((nROI,nROI))

						for index, row in fdat.iterrows():
							srcndx = int(row["src"])
							colndx = int(row["trg"])
							weight = row["nij"] / normalizer

							# uncomment to make the `number of fibers'
							# an integer.  Everything that survived
							# thresholding should be non-zero as
							# Cosica drops zero-valued entries
							#if(weight < 1.0):
							#	weight = int(1.0)
							#else:
							#	weight = int(weight)

							# make the symmetric FSL matrix for output
							fslmat[srcndx][colndx] = weight
							fslmat[colndx][srcndx] = weight

						# save the thresholded matrix in the format
						# that FSL expects to read in
						np.savetxt(fixpath(outputDir) + fdtconnectivity, fslmat, delimiter='  ')
	#------ End internal function definition --------

	if os.path.exists(relative_finished_results_root):
		shutil.rmtree(relative_finished_results_root)

	os.mkdir(relative_finished_results_root)

	# get the list of subject directories
	allsubjects = next(os.walk(relative_cosica_subject_root))[1]

	thissubj   = 0
	totalsubjs = len(allsubjects)
	for subj in allsubjects:
		thissubj += 1
		print("Writing FSL matrix for subject: " + subj)
		printProgressBar(thissubj, totalsubjs, prefix='Writing subject FSL matrices:', suffix='Complete', length=100)
		processSubject(subj)

# ----------------------------------------------------------------


# ----------------------------------------------------------------
#				functions to facilitate multithreading
# ----------------------------------------------------------------
def packagejobs(subjroot=relative_cosica_subject_root, inputfilename=cosicaInput):

	retjobs = {}

	dirlevel = 0
	for rootdir, subjectdirs, files in os.walk(subjroot):

		alljobs = {}
		alljobs['total'] = len(subjectdirs)
		alljobs['joblist'] = []

		thissubj = 0
		dirlevel += 1

		# only process the top level subdirectories (i.e. the
		# subjects, not subdirectories of the subjects)
		if dirlevel == 1:
			for subj in subjectdirs:
				job = {}
				thissubj += 1
				subjdir = os.path.join(relative_cosica_subject_root, subj)

				job['subjdir'] = subjdir
				job['subj'] = subj
				job['inputfile'] = inputfilename

				alljobs['joblist'].append(job)

			retjobs = alljobs

	return retjobs

def execthresholding(jobdetails):
	subjectid = jobdetails['subj']
	subjdir = jobdetails['subjdir']
	inpfile = jobdetails['inputfile']

	print(f"Thresholding beginning for subject with id {subjectid}")

	#--> Test the multi-threading with time.sleep(2)
	generateCosicaThresholds(subjdir, inpfile)
	return f"Job finished for subject with id {subjectid}"

# ----------------------------------------------------------------
# ----------------------------------------------------------------




# ----------------------------------------------------------------
#            Begin thresholding and reformatting process
# ----------------------------------------------------------------


if not os.path.exists(relative_cosica_subject_root):
	print("The relative (to this script) directory {} does not exist".format(relative_cosica_subject_root))
	print("If you need to generate reformatted subject files, please configure and run 1-FSL-to-Cosica.py")
	sys.exit()

# build the thread structure and retrieve the job list
alljobs = packagejobs()
threadjobs = alljobs['joblist']

with concurrent.futures.ThreadPoolExecutor(max_workers=nThreads) as executor:
	futures = []
	for job in threadjobs:
		futures.append(executor.submit(execthresholding, jobdetails=job))
	for future in concurrent.futures.as_completed(futures):
		print(future.result())

# ---------------------------
# Return to serial execution
# ---------------------------
# Convert the Cosica-formatted files to the native FSL format
# and save the
convertCosicaToFSL()

# We have reformatted the Cosica formatted files to the FSL strcutre.
# We can now get rid of the cosica files
shutil.rmtree(relative_cosica_subject_root)